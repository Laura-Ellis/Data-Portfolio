{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ff694-ee62-49b9-bfc8-3b328617b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Setup script to scaffold data portfolio projects.\n",
    "\n",
    "Usage:\n",
    "    python setup_portfolio_projects.py --project global-infectious-disease-surveillance\n",
    "    python setup_portfolio_projects.py --all\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "\n",
    "PROJECTS = {\n",
    "    \"global-infectious-disease-surveillance\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"data_ingestion\",\n",
    "            \"modeling\",\n",
    "            \"nlp_analysis\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"scikit-learn\",\n",
    "            \"prophet\", \"requests\", \"keybert\", \"nltk\", \"geopandas\", \"pycountry\",\n",
    "            \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"Global infectious disease outbreak analysis & forecasting.\",\n",
    "    },\n",
    "    \"us-flight-delay-prediction\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"cleaning\",\n",
    "            \"feature_engineering\",\n",
    "            \"models/saved_models\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"scikit-learn\",\n",
    "            \"xgboost\", \"lightgbm\", \"requests\", \"holidays\", \"jupyter\",\n",
    "            \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"US DOT flight delay prediction with weather & congestion features.\",\n",
    "    },\n",
    "    \"retail-customer-segmentation\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"rfm\",\n",
    "            \"clustering\",\n",
    "            \"nlp\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\", \"scikit-learn\",\n",
    "            \"umap-learn\", \"textblob\", \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"RFM + clustering segmentation on ecommerce customers.\",\n",
    "    },\n",
    "    \"crypto-anomaly-detection\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"api\",\n",
    "            \"lstm\",\n",
    "            \"volatility\",\n",
    "            \"sentiment\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"torch\", \"statsmodels\", \"arch\",\n",
    "            \"requests\", \"textblob\", \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"LSTM + anomaly detection on cryptocurrency time series.\",\n",
    "    },\n",
    "    \"supply-chain-risk-index\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"trade_api\",\n",
    "            \"nlp\",\n",
    "            \"risk_model\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"networkx\", \"requests\", \"spacy\",\n",
    "            \"textblob\", \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"Supply chain risk scoring from trade flows + disruption news.\",\n",
    "    },\n",
    "    \"esg-reporting-classifier\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw_filings\",\n",
    "            \"data/processed\",\n",
    "            \"sec_scraper\",\n",
    "            \"bert_model\",\n",
    "            \"topic_modeling\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"torch\", \"transformers\", \"datasets\",\n",
    "            \"sentencepiece\", \"bertopic\", \"umap-learn\", \"hdbscan\",\n",
    "            \"beautifulsoup4\", \"lxml\", \"requests\", \"jupyter\",\n",
    "            \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"BERT-based ESG classifier for SEC filings.\",\n",
    "    },\n",
    "    \"energy-demand-forecasting\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"eia_api\",\n",
    "            \"weather\",\n",
    "            \"forecasting\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"prophet\", \"torch\",\n",
    "            \"statsmodels\", \"requests\", \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"Energy load forecasting using EIA + NOAA weather.\",\n",
    "    },\n",
    "    \"restaurant-inspection-prediction\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"cleaning\",\n",
    "            \"classification\",\n",
    "            \"menu_scraper\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"geopandas\", \"shapely\",\n",
    "            \"requests\", \"beautifulsoup4\", \"lxml\",\n",
    "            \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"Predicting restaurant inspection risk in NYC.\",\n",
    "    },\n",
    "    \"natural-disaster-damage-cv\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw/before\",\n",
    "            \"data/raw/after\",\n",
    "            \"data/processed\",\n",
    "            \"satellite_data\",\n",
    "            \"preprocessing\",\n",
    "            \"cnn_model\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"torch\", \"torchvision\", \"rasterio\", \"opencv-python\",\n",
    "            \"albumentations\", \"geopandas\", \"shapely\",\n",
    "            \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"CV model on Sentinel-2 imagery for damage classification.\",\n",
    "    },\n",
    "    \"fake-news-detection-transformers\": {\n",
    "        \"folders\": [\n",
    "            \"data/raw\",\n",
    "            \"data/processed\",\n",
    "            \"datasets_loader\",\n",
    "            \"transformer_model\",\n",
    "            \"analysis\",\n",
    "            \"notebooks\",\n",
    "            \"tableau\",\n",
    "            \"utils\",\n",
    "        ],\n",
    "        \"requirements\": [\n",
    "            \"pandas\", \"numpy\", \"matplotlib\", \"seaborn\",\n",
    "            \"scikit-learn\", \"torch\", \"transformers\",\n",
    "            \"datasets\", \"umap-learn\", \"hdbscan\", \"nltk\",\n",
    "            \"jupyter\", \"python-dotenv\"\n",
    "        ],\n",
    "        \"description\": \"Transformer-based fake news detection & reliability analysis.\",\n",
    "    },\n",
    "}\n",
    "\n",
    "CONFIG_TEMPLATE = dedent(\n",
    "    \"\"\"\\\n",
    "    \\\"\\\"\\\" \n",
    "    Central configuration for paths, API keys, and runtime settings.\n",
    "    Generated for project: {project_name}\n",
    "    \\\"\\\"\\\" \n",
    "\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "    except ImportError:\n",
    "        # dotenv is optional\n",
    "        pass\n",
    "\n",
    "    BASE_DIR: Path = Path(__file__).resolve().parent\n",
    "\n",
    "    DATA_DIR: Path = BASE_DIR / \"data\"\n",
    "    RAW_DATA_DIR: Path = DATA_DIR / \"raw\"\n",
    "    PROCESSED_DATA_DIR: Path = DATA_DIR / \"processed\"\n",
    "\n",
    "    NOTEBOOKS_DIR: Path = BASE_DIR / \"notebooks\"\n",
    "    TABLEAU_DIR: Path = BASE_DIR / \"tableau\"\n",
    "    MODELS_DIR: Path = BASE_DIR / \"models\"\n",
    "    LOGS_DIR: Path = BASE_DIR / \"logs\"\n",
    "    SRC_DIR: Path = BASE_DIR / \"src\"  # optional generic source folder\n",
    "\n",
    "    for _p in [DATA_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR,\n",
    "               NOTEBOOKS_DIR, TABLEAU_DIR, MODELS_DIR, LOGS_DIR]:\n",
    "        _p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    def get_env(name: str, default: str | None = None) -> str | None:\n",
    "        \\\"\\\"\\\"Get environment variable with optional default.\\\"\\\"\\\"\n",
    "        return os.getenv(name, default)\n",
    "\n",
    "\n",
    "    def require_env(name: str) -> str:\n",
    "        \\\"\\\"\\\"Get an env var or raise helpful error if missing.\\\"\\\"\\\"\n",
    "        value = os.getenv(name)\n",
    "        if not value:\n",
    "            raise RuntimeError(\n",
    "                f\"Required environment variable '{name}' is not set. \"\n",
    "                f\"Set it in your shell or in a .env file at {BASE_DIR}\"\n",
    "            )\n",
    "        return value\n",
    "\n",
    "\n",
    "    # Common API keys (only use what you need in this project)\n",
    "    WHO_API_KEY = get_env(\"WHO_API_KEY\")\n",
    "    DOT_API_KEY = get_env(\"DOT_API_KEY\")\n",
    "    NOAA_API_KEY = get_env(\"NOAA_API_KEY\")\n",
    "    EIA_API_KEY = get_env(\"EIA_API_KEY\")\n",
    "    NEWS_API_KEY = get_env(\"NEWS_API_KEY\")\n",
    "    UN_COMTRADE_API_KEY = get_env(\"UN_COMTRADE_API_KEY\")\n",
    "    SEC_EDGAR_API_KEY = get_env(\"SEC_EDGAR_API_KEY\")\n",
    "    FEMA_API_KEY = get_env(\"FEMA_API_KEY\")\n",
    "    COINGECKO_API_KEY = get_env(\"COINGECKO_API_KEY\")\n",
    "\n",
    "    ASANA_PAT = get_env(\"ASANA_PAT\")\n",
    "    GITHUB_TOKEN = get_env(\"GITHUB_TOKEN\")\n",
    "\n",
    "    SETTINGS = {{\n",
    "        \"ENV\": get_env(\"ENV\", \"dev\"),\n",
    "        \"MAX_ROWS_DEV\": int(get_env(\"MAX_ROWS_DEV\", \"50000\")),\n",
    "        \"CACHE_DIR\": str(BASE_DIR / \".cache\"),\n",
    "        \"LOG_LEVEL\": get_env(\"LOG_LEVEL\", \"INFO\"),\n",
    "    }}\n",
    "\n",
    "    CACHE_DIR = Path(SETTINGS[\"CACHE_DIR\"])\n",
    "    CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def create_project(name: str) -> None:\n",
    "    if name not in PROJECTS:\n",
    "        raise SystemExit(f\"Unknown project '{name}'. Valid: {', '.join(PROJECTS)}\")\n",
    "\n",
    "    meta = PROJECTS[name]\n",
    "    project_dir = BASE_DIR / name\n",
    "    project_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Folders\n",
    "    for f in meta[\"folders\"]:\n",
    "        (project_dir / f).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # README\n",
    "    readme_path = project_dir / \"README.md\"\n",
    "    if not readme_path.exists():\n",
    "        readme_content = dedent(\n",
    "            f\"\"\"\\\n",
    "            # {name}\n",
    "\n",
    "            {meta['description']}\n",
    "\n",
    "            ## Quick Start\n",
    "\n",
    "            ```bash\n",
    "            pip install -r requirements.txt\n",
    "            # Add your run commands here\n",
    "            ```\n",
    "\n",
    "            \"\"\"\n",
    "        )\n",
    "        readme_path.write_text(readme_content, encoding=\"utf-8\")\n",
    "\n",
    "    # requirements.txt\n",
    "    req_path = project_dir / \"requirements.txt\"\n",
    "    if not req_path.exists():\n",
    "        req_text = \"\\n\".join(sorted(set(meta[\"requirements\"]))) + \"\\n\"\n",
    "        req_path.write_text(req_text, encoding=\"utf-8\")\n",
    "\n",
    "    # config.py\n",
    "    config_path = project_dir / \"config.py\"\n",
    "    if not config_path.exists():\n",
    "        config_path.write_text(CONFIG_TEMPLATE.format(project_name=name), encoding=\"utf-8\")\n",
    "\n",
    "    # starter notebooks\n",
    "    nb1 = project_dir / \"notebooks\" / \"01_eda.ipynb\"\n",
    "    nb2 = project_dir / \"notebooks\" / \"02_modeling.ipynb\"\n",
    "    if not nb1.exists():\n",
    "        # minimal empty notebooks; you can overwrite later\n",
    "        empty_nb = {\n",
    "            \"cells\": [],\n",
    "            \"metadata\": {},\n",
    "            \"nbformat\": 4,\n",
    "            \"nbformat_minor\": 5,\n",
    "        }\n",
    "        import json\n",
    "\n",
    "        nb1.write_text(json.dumps(empty_nb, indent=2), encoding=\"utf-8\")\n",
    "        nb2.write_text(json.dumps(empty_nb, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"âœ” Created/updated scaffold for {name}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--project\",\n",
    "        help=\"Name of project to set up (see PROJECTS dict).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--all\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Create all projects defined in this script.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.all:\n",
    "        for name in PROJECTS:\n",
    "            create_project(name)\n",
    "    elif args.project:\n",
    "        create_project(args.project)\n",
    "    else:\n",
    "        parser.print_help()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00893daf-8575-4e19-bfbb-d6a8b0868628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
