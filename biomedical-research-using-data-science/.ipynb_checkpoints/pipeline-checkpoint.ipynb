{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386eb24-609a-4b09-a0f8-240f32a965ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pipeline for biomedical research analysis using NIH RePORTER / ExPORTER data.\n",
    "\n",
    "Goals:\n",
    "- Load NIH project (grant) data from ExPORTER/REPORTER CSVs.\n",
    "- Filter to a biomedical topic (e.g., asthma, HIV, cancer).\n",
    "- Build summary tables: funding trends, IC distribution, mechanisms.\n",
    "- (Optional) Link to publications for bibliometrics / NLP.\n",
    "- Export processed datasets ready for further analysis or dashboards.\n",
    "\n",
    "Usage (examples):\n",
    "    python pipeline_nih_biomedical.py --fy-start 2019 --fy-end 2024 --keyword asthma\n",
    "    python pipeline_nih_biomedical.py --fy-start 2015 --fy-end 2020 --rcdc \"Asthma\"\n",
    "\n",
    "Assumptions:\n",
    "- You have downloaded NIH ExPORTER / RePORTER project CSVs into data/raw.\n",
    "- Filenames look like: RePORTER_PRJ_C_FY2019.csv, etc.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Minimal config (works even if you don't have a separate config.py)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from config import RAW_DATA_DIR, PROCESSED_DATA_DIR  # type: ignore\n",
    "except ImportError:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "    RAW_DATA_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "    PROCESSED_DATA_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Config dataclass\n",
    "# ---------------------------------------------------------------------\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    fy_start: int\n",
    "    fy_end: int\n",
    "    keyword: Optional[str] = None\n",
    "    rcdc_term: Optional[str] = None\n",
    "    exporter_prefix: str = \"RePORTER_PRJ_C_FY\"  # adjust if names differ\n",
    "    project_id_col: str = \"PROJECT_NUMBER\"\n",
    "    abstract_col: str = \"ABSTRACT_TEXT\"\n",
    "    title_col: str = \"PROJECT_TITLE\"\n",
    "    rcdc_col: str = \"PROJECT_TERMS\"  # or \"RCDC\" depending on file\n",
    "    out_prefix: str = \"nih_biomed\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Data loading\n",
    "# ---------------------------------------------------------------------\n",
    "def find_exporter_files(cfg: PipelineConfig) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Locate NIH RePORTER/ExPORTER project CSVs for the FY range.\n",
    "    Assumes filenames contain FY year like 'RePORTER_PRJ_C_FY2019.csv'.\n",
    "    \"\"\"\n",
    "    files: List[Path] = []\n",
    "    for fy in range(cfg.fy_start, cfg.fy_end + 1):\n",
    "        pattern = f\"{cfg.exporter_prefix}{fy}\"\n",
    "        options = list(RAW_DATA_DIR.glob(f\"{pattern}*.csv\"))\n",
    "        if not options:\n",
    "            print(f\"[WARN] No file found for FY {fy} matching {pattern}*.csv\")\n",
    "        else:\n",
    "            files.extend(options)\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_nih_projects(cfg: PipelineConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and concatenate NIH project-level CSVs for the requested FY range.\n",
    "    \"\"\"\n",
    "    files = find_exporter_files(cfg)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No NIH project files found in {RAW_DATA_DIR} for FY {cfg.fy_start}-{cfg.fy_end}.\\n\"\n",
    "            \"Download RePORTER/ExPORTER project files from NIH and place them in data/raw.\"\n",
    "        )\n",
    "\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        print(f\"[INFO] Reading {f.name}\")\n",
    "        df = pd.read_csv(f, dtype=str, low_memory=False)\n",
    "        dfs.append(df)\n",
    "\n",
    "    projects = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"[INFO] Loaded {len(projects):,} project rows from {len(files)} file(s).\")\n",
    "    return projects\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Filtering & text processing\n",
    "# ---------------------------------------------------------------------\n",
    "def filter_by_fy(projects: pd.DataFrame, cfg: PipelineConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter projects by fiscal year (if present in the data).\n",
    "    ExPORTER often uses 'FY' or 'FISCAL_YEAR' column.\n",
    "    \"\"\"\n",
    "    fy_cols = [c for c in projects.columns if c.upper() in {\"FY\", \"FISCAL_YEAR\"}]\n",
    "    if not fy_cols:\n",
    "        print(\"[WARN] No FY/FISCAL_YEAR column found; skipping FY filter.\")\n",
    "        return projects\n",
    "\n",
    "    fy_col = fy_cols[0]\n",
    "    projects[fy_col] = pd.to_numeric(projects[fy_col], errors=\"coerce\")\n",
    "    mask = (projects[fy_col] >= cfg.fy_start) & (projects[fy_col] <= cfg.fy_end)\n",
    "    filtered = projects.loc[mask].copy()\n",
    "    print(f\"[INFO] Filtered to FY {cfg.fy_start}-{cfg.fy_end}: {len(filtered):,} rows remain.\")\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def filter_by_keyword(projects: pd.DataFrame, cfg: PipelineConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter based on a keyword in project title or abstract (case-insensitive).\n",
    "    \"\"\"\n",
    "    if not cfg.keyword:\n",
    "        return projects\n",
    "\n",
    "    kw = cfg.keyword.lower()\n",
    "    title_col = cfg.title_col if cfg.title_col in projects.columns else None\n",
    "    abstract_col = cfg.abstract_col if cfg.abstract_col in projects.columns else None\n",
    "\n",
    "    if not title_col and not abstract_col:\n",
    "        print(\"[WARN] No title/abstract columns found; skipping keyword filter.\")\n",
    "        return projects\n",
    "\n",
    "    def text_contains(s: pd.Series) -> pd.Series:\n",
    "        return s.fillna(\"\").str.lower().str.contains(kw, na=False)\n",
    "\n",
    "    mask = pd.Series(False, index=projects.index)\n",
    "    if title_col:\n",
    "        mask |= text_contains(projects[title_col])\n",
    "    if abstract_col:\n",
    "        mask |= text_contains(projects[abstract_col])\n",
    "\n",
    "    filtered = projects.loc[mask].copy()\n",
    "    print(f\"[INFO] Filtered by keyword '{cfg.keyword}': {len(filtered):,} rows remain.\")\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def filter_by_rcdc(projects: pd.DataFrame, cfg: PipelineConfig) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter based on RCDC or term column (depending on how your ExPORTER is structured).\n",
    "    \"\"\"\n",
    "    if not cfg.rcdc_term:\n",
    "        return projects\n",
    "\n",
    "    col = cfg.rcdc_col if cfg.rcdc_col in projects.columns else None\n",
    "    if not col:\n",
    "        print(f\"[WARN] RCDC/term column '{cfg.rcdc_col}' not found; skipping RCDC filter.\")\n",
    "        return projects\n",
    "\n",
    "    term = cfg.rcdc_term.lower()\n",
    "    mask = projects[col].fillna(\"\").str.lower().str.contains(term, na=False)\n",
    "    filtered = projects.loc[mask].copy()\n",
    "    print(f\"[INFO] Filtered by RCDC term '{cfg.rcdc_term}': {len(filtered):,} rows remain.\")\n",
    "    return filtered\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Summary tables\n",
    "# ---------------------------------------------------------------------\n",
    "def summarize_by_fy(projects: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Funding trends by fiscal year.\n",
    "    Assumes a 'TOTAL_COST' or similar; adjust as needed for your ExPORTER schema.\n",
    "    \"\"\"\n",
    "    df = projects.copy()\n",
    "    fy_cols = [c for c in df.columns if c.upper() in {\"FY\", \"FISCAL_YEAR\"}]\n",
    "    if not fy_cols:\n",
    "        print(\"[WARN] No FY column for summary; returning empty frame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    fy_col = fy_cols[0]\n",
    "    df[fy_col] = pd.to_numeric(df[fy_col], errors=\"coerce\")\n",
    "\n",
    "    funding_cols = [c for c in df.columns if \"TOTAL_COST\" in c.upper()]\n",
    "    if funding_cols:\n",
    "        fund_col = funding_cols[0]\n",
    "        df[fund_col] = pd.to_numeric(df[fund_col], errors=\"coerce\")\n",
    "        agg = df.groupby(fy_col)[fund_col].sum().reset_index()\n",
    "        agg.rename(columns={fund_col: \"total_cost\"}, inplace=True)\n",
    "    else:\n",
    "        agg = df.groupby(fy_col)[df.columns[0]].count().reset_index()\n",
    "        agg.rename(columns={df.columns[0]: \"project_count\"}, inplace=True)\n",
    "\n",
    "    return agg.sort_values(by=fy_col)\n",
    "\n",
    "\n",
    "def summarize_by_ic(projects: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summary by NIH Institute/Center.\n",
    "    Assumes an 'IC_NAME' or 'IC' column.\n",
    "    \"\"\"\n",
    "    df = projects.copy()\n",
    "    ic_cols = [c for c in df.columns if c.upper() in {\"IC_NAME\", \"IC\", \"ADMIN_IC\"}]\n",
    "    if not ic_cols:\n",
    "        print(\"[WARN] No IC column found for summary; returning empty frame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    ic_col = ic_cols[0]\n",
    "    funding_cols = [c for c in df.columns if \"TOTAL_COST\" in c.upper()]\n",
    "    if funding_cols:\n",
    "        fund_col = funding_cols[0]\n",
    "        df[fund_col] = pd.to_numeric(df[fund_col], errors=\"coerce\")\n",
    "        agg = df.groupby(ic_col)[fund_col].sum().reset_index()\n",
    "        agg.rename(columns={fund_col: \"total_cost\"}, inplace=True)\n",
    "    else:\n",
    "        agg = df.groupby(ic_col)[df.columns[0]].count().reset_index()\n",
    "        agg.rename(columns={df.columns[0]: \"project_count\"}, inplace=True)\n",
    "\n",
    "    return agg.sort_values(by=\"total_cost\" if \"total_cost\" in agg.columns else \"project_count\", ascending=False)\n",
    "\n",
    "\n",
    "def summarize_by_mechanism(projects: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summary by activity code / mechanism (e.g., R01, U01, K23).\n",
    "    \"\"\"\n",
    "    df = projects.copy()\n",
    "    act_cols = [c for c in df.columns if c.upper() in {\"ACTIVITY\", \"ACTIVITY_CODE\"}]\n",
    "    if not act_cols:\n",
    "        print(\"[WARN] No activity code column found; returning empty frame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    act_col = act_cols[0]\n",
    "    funding_cols = [c for c in df.columns if \"TOTAL_COST\" in c.upper()]\n",
    "    if funding_cols:\n",
    "        fund_col = funding_cols[0]\n",
    "        df[fund_col] = pd.to_numeric(df[fund_col], errors=\"coerce\")\n",
    "        agg = df.groupby(act_col)[fund_col].sum().reset_index()\n",
    "        agg.rename(columns={fund_col: \"total_cost\"}, inplace=True)\n",
    "    else:\n",
    "        agg = df.groupby(act_col)[df.columns[0]].count().reset_index()\n",
    "        agg.rename(columns={df.columns[0]: \"project_count\"}, inplace=True)\n",
    "\n",
    "    return agg.sort_values(by=\"total_cost\" if \"total_cost\" in agg.columns else \"project_count\", ascending=False)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Optional: publications / text corpus (placeholder)\n",
    "# ---------------------------------------------------------------------\n",
    "def load_project_publication_links() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Optional: load NIH ExPORTER project-publication link file if available, e.g.:\n",
    "        RePORTER_PUB_C_FY2019.csv\n",
    "    Place it in data/raw and adjust filename as needed.\n",
    "\n",
    "    Returns a DataFrame linking project numbers to PMIDs.\n",
    "    \"\"\"\n",
    "    # Adjust the filename to whatever you have locally\n",
    "    link_files = list(RAW_DATA_DIR.glob(\"RePORTER_PUB_C_FY*.csv\"))\n",
    "    if not link_files:\n",
    "        print(\"[INFO] No publication link files found; skipping publication step.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    dfs = []\n",
    "    for f in link_files:\n",
    "        print(f\"[INFO] Reading pub link file {f.name}\")\n",
    "        df = pd.read_csv(f, dtype=str, low_memory=False)\n",
    "        dfs.append(df)\n",
    "    links = pd.concat(dfs, ignore_index=True)\n",
    "    return links\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def run_pipeline(cfg: PipelineConfig) -> None:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline:\n",
    "\n",
    "    1. Load NIH project data for FY range.\n",
    "    2. Filter by FY, keyword, RCDC term.\n",
    "    3. Build and export summary tables.\n",
    "    4. (Optional) Load project-publication links for bibliometrics.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Running NIH biomedical pipeline for FY {cfg.fy_start}-{cfg.fy_end}\")\n",
    "    projects = load_nih_projects(cfg)\n",
    "    projects = filter_by_fy(projects, cfg)\n",
    "    projects = filter_by_keyword(projects, cfg)\n",
    "    projects = filter_by_rcdc(projects, cfg)\n",
    "\n",
    "    if projects.empty:\n",
    "        print(\"[WARN] No projects after filters; exiting.\")\n",
    "        return\n",
    "\n",
    "    # Core summaries\n",
    "    fy_summary = summarize_by_fy(projects)\n",
    "    ic_summary = summarize_by_ic(projects)\n",
    "    mech_summary = summarize_by_mechanism(projects)\n",
    "\n",
    "    PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Export filtered projects and summaries\n",
    "    projects_out = PROCESSED_DATA_DIR / f\"{cfg.out_prefix}_projects_fy{cfg.fy_start}_{cfg.fy_end}.csv\"\n",
    "    fy_out = PROCESSED_DATA_DIR / f\"{cfg.out_prefix}_fy_summary.csv\"\n",
    "    ic_out = PROCESSED_DATA_DIR / f\"{cfg.out_prefix}_ic_summary.csv\"\n",
    "    mech_out = PROCESSED_DATA_DIR / f\"{cfg.out_prefix}_mechanism_summary.csv\"\n",
    "\n",
    "    projects.to_csv(projects_out, index=False)\n",
    "    fy_summary.to_csv(fy_out, index=False)\n",
    "    ic_summary.to_csv(ic_out, index=False)\n",
    "    mech_summary.to_csv(mech_out, index=False)\n",
    "\n",
    "    print(f\"[INFO] Exported filtered projects to: {projects_out}\")\n",
    "    print(f\"[INFO] Exported FY summary to:     {fy_out}\")\n",
    "    print(f\"[INFO] Exported IC summary to:     {ic_out}\")\n",
    "    print(f\"[INFO] Exported mechanism summary to: {mech_out}\")\n",
    "\n",
    "    # Optional: project-publication links\n",
    "    pub_links = load_project_publication_links()\n",
    "    if not pub_links.empty:\n",
    "        # TODO: join pub_links to projects, build corpus, run topic modeling, etc.\n",
    "        # Example join key may be \"PROJECT_NUMBER\" or \"APPLICATION_ID\"\n",
    "        print(f\"[INFO] Loaded {len(pub_links):,} project-publication links (implement join in a notebook).\")\n",
    "\n",
    "\n",
    "def parse_args() -> PipelineConfig:\n",
    "    parser = argparse.ArgumentParser(description=\"NIH Biomedical Data Science Pipeline\")\n",
    "    parser.add_argument(\"--fy-start\", type=int, required=True, help=\"Start fiscal year (e.g., 2019)\")\n",
    "    parser.add_argument(\"--fy-end\", type=int, required=True, help=\"End fiscal year (e.g., 2024)\")\n",
    "    parser.add_argument(\"--keyword\", type=str, default=None, help=\"Text keyword for title/abstract filter\")\n",
    "    parser.add_argument(\"--rcdc\", type=str, default=None, help=\"RCDC term or project term substring filter\")\n",
    "    parser.add_argument(\"--out-prefix\", type=str, default=\"nih_biomed\", help=\"Prefix for output files\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return PipelineConfig(\n",
    "        fy_start=args.fy_start,\n",
    "        fy_end=args.fy_end,\n",
    "        keyword=args.keyword,\n",
    "        rcdc_term=args.rcdc,\n",
    "        out_prefix=args.out_prefix,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg_ = parse_args()\n",
    "    run_pipeline(cfg_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
